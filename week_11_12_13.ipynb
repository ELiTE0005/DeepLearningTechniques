{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ELiTE0005/DeepLearningTechniques/blob/main/week_11_12_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 11"
      ],
      "metadata": {
        "id": "OHjavUau11YP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54KtRHuFlCKU",
        "outputId": "3bca23ab-3029-454b-d33c-974863dc4111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 134MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 40.1MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 64.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.91MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch shape: torch.Size([64, 784])\n",
            "Sample mu: [-0.06443769484758377, -0.02626766264438629, 0.04772452265024185, 0.06973494589328766]\n",
            "Loss: 35269.0547\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc_mu = nn.Linear(400, 20)\n",
        "        self.fc_logvar = nn.Linear(400, 20)\n",
        "        self.fc2 = nn.Linear(20, 400)\n",
        "        self.fc3 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = torch.relu(self.fc1(x))\n",
        "        return self.fc_mu(h), self.fc_logvar(h)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = (0.5 * logvar).exp()\n",
        "        return mu + std * torch.randn_like(std)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = torch.relu(self.fc2(z))\n",
        "        return torch.sigmoid(self.fc3(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar, z\n",
        "\n",
        "def loss_fn(recon, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "\n",
        "model = VAE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "data, _ = next(iter(train_loader))\n",
        "data = data.view(-1, 784)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "recon, mu, logvar, z = model(data)\n",
        "loss = loss_fn(recon, data, mu, logvar)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(f\"Input batch shape: {data.shape}\")\n",
        "print(f\"Sample mu: {mu[0, :4].tolist()}\")\n",
        "print(f\"Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 12"
      ],
      "metadata": {
        "id": "wqL7HO4DU1h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal Deep Convolutional GAN (DCGAN) for color image generation\n",
        "import torch, torch.nn as nn, torch.optim as optim, torchvision as tv\n",
        "\n",
        "# 1. Load CIFAR-10 dataset (color images)\n",
        "tf = tv.transforms.Compose([\n",
        "    tv.transforms.Resize(32),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((.5,)*3, (.5,)*3)   # normalize to [-1,1]\n",
        "])\n",
        "dl = torch.utils.data.DataLoader(tv.datasets.CIFAR10('.', True, tf, download=True), 128, True)\n",
        "\n",
        "# 2. Basic setup\n",
        "nz = 100                              # latent vector (noise) size\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 3. Generator network (upsamples noise → fake color image)\n",
        "G = nn.Sequential(\n",
        "    nn.ConvTranspose2d(nz,256,4,1,0), nn.ReLU(True),\n",
        "    nn.ConvTranspose2d(256,128,4,2,1), nn.ReLU(True),\n",
        "    nn.ConvTranspose2d(128,64,4,2,1), nn.ReLU(True),\n",
        "    nn.ConvTranspose2d(64,3,4,2,1), nn.Tanh()    # output 3-channel image\n",
        ").to(device)\n",
        "\n",
        "# 4. Discriminator network (downsamples image → real/fake)\n",
        "D = nn.Sequential(\n",
        "    nn.Conv2d(3,64,4,2,1), nn.LeakyReLU(.2,True),\n",
        "    nn.Conv2d(64,128,4,2,1), nn.LeakyReLU(.2,True),\n",
        "    nn.Conv2d(128,1,4,2,1), nn.Sigmoid()        # outputs probability\n",
        ").to(device)\n",
        "\n",
        "# 5. Loss and optimizers\n",
        "optG = optim.Adam(G.parameters(), lr=2e-4, betas=(.5,.999))\n",
        "optD = optim.Adam(D.parameters(), lr=2e-4, betas=(.5,.999))\n",
        "loss = nn.BCELoss()   # binary cross entropy loss\n",
        "\n",
        "# 6. Training loop (adversarial training)\n",
        "for epoch in range(2):   # small epochs for demo\n",
        "  for x,_ in dl:\n",
        "    x = x.to(device); b = x.size(0)\n",
        "    r, f = torch.ones(b,device=device), torch.zeros(b,device=device)\n",
        "\n",
        "    # --- Train Discriminator ---\n",
        "    D.zero_grad()\n",
        "    l1 = loss(D(x).view(b,-1).mean(1), r)                # real images\n",
        "    z = torch.randn(b,nz,1,1,device=device)\n",
        "    fake = G(z)\n",
        "    l2 = loss(D(fake.detach()).view(b,-1).mean(1), f)    # fake images\n",
        "    (l1+l2).backward(); optD.step()\n",
        "\n",
        "    # --- Train Generator ---\n",
        "    G.zero_grad()\n",
        "    l3 = loss(D(fake).view(b,-1).mean(1), r)             # wants D to think fake = real\n",
        "    l3.backward(); optG.step()\n",
        "  print(f\"Epoch {epoch+1} complete\")\n",
        "\n",
        "# 7. Save sample generated images\n",
        "tv.utils.save_image((G(torch.randn(16,nz,1,1,device=device)).cpu()+1)/2, \"gen.png\", nrow=4)\n",
        "print(\"Generated images saved as gen.png\")\n"
      ],
      "metadata": {
        "id": "v8gTz4KLlzf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97539467-b7ac-4649-bd89-418cec1eaf49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 84.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete\n",
            "Epoch 2 complete\n",
            "Generated images saved as gen.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 13"
      ],
      "metadata": {
        "id": "y1PQFtiS1zkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pre-trained ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze convolutional layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the classification head for new task (5 classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, 5)\n",
        "\n",
        "# Print only the new head and trainable layers\n",
        "print(\"Modified classification head:\", model.fc)\n",
        "trainable = [name for name, p in model.named_parameters() if p.requires_grad]\n",
        "print(\"Trainable layers:\", trainable)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FgYoVSQU4TW",
        "outputId": "d1ba6fbd-d2e4-49b4-8835-7eb76e4d4451"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 153MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified classification head: Linear(in_features=512, out_features=5, bias=True)\n",
            "Trainable layers: ['fc.weight', 'fc.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9a3NfshZtDu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}